{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the data\n",
    "#types = [np.int32,np.int32,np.int32,None,np.int32,None,None]\n",
    "off_train = pd.read_csv('./coupon/ccf_offline_stage1_train.csv',dtype=str)\n",
    "COLUMNS = ['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']\n",
    "off_train.columns = COLUMNS\n",
    "#print(off_train.head())\n",
    "\n",
    "off_test = pd.read_csv('./coupon/ccf_offline_stage1_test_revised.csv',dtype=str)\n",
    "off_test.columns = COLUMNS[:-1]\n",
    "#print(off_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datesetsplit\n",
    "''' (date_received)                              \n",
    "           dateset3: 20160701~20160731 (113640),features3 from 20160315~20160630  (off_test)\n",
    "           dateset2: 20160515~20160615 (258446),features2 from 20160201~20160514  \n",
    "           dateset1: 20160414~20160514 (138303),features1 from 20160101~20160413'''\n",
    "dataset3 = off_test\n",
    "feature3 = off_train[((off_train.date>='20160315')&(off_train.date<='20160630'))|((off_train.date.isnull())&(off_train.date_received>='20160315')&(off_train.date_received<='20160630'))]\n",
    "dataset2 = off_train[(off_train.date_received>='20160515')&(off_train.date_received<='20160615')]\n",
    "feature2 = off_train[(off_train.date>='20160201')&(off_train.date<='20160514')|((off_train.date.isnull())&(off_train.date_received>='20160201')&(off_train.date_received<='20160514'))]\n",
    "dataset1 = off_train[(off_train.date_received>='20160414')&(off_train.date_received<='20160514')]\n",
    "feature1 = off_train[(off_train.date>='20160101')&(off_train.date<='20160413')|((off_train.date.isnull())&(off_train.date_received>='20160101')&(off_train.date_received<='20160413'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113640, 6) (258446, 7) (137167, 7)\n",
      "(1036975, 7) (812779, 7) (995240, 7)\n"
     ]
    }
   ],
   "source": [
    "print(dataset3.shape,dataset2.shape,dataset1.shape)\n",
    "print(feature3.shape,feature2.shape,feature1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# merchant related feature   #############\n",
    "\"\"\"\n",
    "1.merchant related: \n",
    "      total_sales. sales_use_coupon.  total_coupon\n",
    "      coupon_rate = sales_use_coupon/total_sales.  \n",
    "      transfer_rate = sales_use_coupon/total_coupon. \n",
    "      merchant_avg_distance,merchant_min_distance,merchant_max_distance of those use coupon\n",
    "\"\"\"\n",
    "def merchants_feature_extract(set_name,data_set,feature_cols=['merchant_id','coupon_id','distance','date_received','date']):\n",
    "    merchant = data_set[feature_cols].copy()\n",
    "    t = merchant[['merchant_id']].copy()\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    \n",
    "    t1 = merchant[~merchant.date.isnull()][['merchant_id']].copy()\n",
    "    t1['total_sales'] = 1\n",
    "    t1 = t1.groupby('merchant_id').agg('sum').reset_index()\n",
    "    \n",
    "    t2 = merchant[(~merchant.date.isnull())&(~merchant.coupon_id.isnull())][['merchant_id']].copy()    \n",
    "    t2['sales_use_coupon'] = 1   \n",
    "    t2 = t2.groupby('merchant_id').agg('sum').reset_index()\n",
    "    \n",
    "    t3 = merchant[~merchant.coupon_id.isnull()][['merchant_id']].copy()\n",
    "    t3['total_coupon'] = 1\n",
    "    t3 = t3.groupby('merchant_id').agg('sum').reset_index()\n",
    "    \n",
    "    t4 = merchant[(~merchant.date.isnull())&(~merchant.coupon_id.isnull())][['merchant_id','distance']].copy()\n",
    "    #t4.distance=np.where(~t4.distance.isnull(),t4.distance,-1)[0]\n",
    "    t4.replace(np.nan,-1,inplace=True)\n",
    "    t4.distance = t4.distance.astype('int')  # can be astype(int)\n",
    "    t4.replace(-1,np.nan,inplace=True)\n",
    "    \n",
    "    def distance_feature(df,feature,new_name):\n",
    "        df1 = df.groupby('merchant_id').agg(feature).reset_index()\n",
    "        df1.rename(columns={'distance':new_name},inplace=True)\n",
    "        return df1\n",
    "    \n",
    "    t5 = distance_feature(t4,'min','merchant_min_distance')\n",
    "    t6 = distance_feature(t4,'max','merchant_max_distance')\n",
    "    t7 = distance_feature(t4,'mean','merchant_mean_distance')\n",
    "    t8 = distance_feature(t4,'median','merchant_median_distance')\n",
    "    \n",
    "    merchant_feature = pd.merge(t,t1,on='merchant_id',how='left')\n",
    "    merchant_feature = pd.merge(merchant_feature,t2,on='merchant_id',how='left')\n",
    "    merchant_feature = pd.merge(merchant_feature,t3,on='merchant_id',how='left')\n",
    "    merchant_feature = pd.merge(merchant_feature,t5,on='merchant_id',how='left')\n",
    "    merchant_feature = pd.merge(merchant_feature,t6,on='merchant_id',how='left')\n",
    "    merchant_feature = pd.merge(merchant_feature,t7,on='merchant_id',how='left')\n",
    "    merchant_feature = pd.merge(merchant_feature,t8,on='merchant_id',how='left')\n",
    "    merchant_feature['sales_use_coupon'] = merchant_feature['sales_use_coupon'].replace(np.nan,0)\n",
    "    merchant_feature['merchant_coupon_transfer_rate'] = merchant_feature.sales_use_coupon.astype('float').div(merchant_feature.total_coupon)\n",
    "    merchant_feature['coupon_rate'] = merchant_feature.sales_use_coupon.astype('float').div(merchant_feature.total_sales)\n",
    "    merchant_feature['total_coupon'] = merchant_feature['total_coupon'].fillna(0)\n",
    "    merchant_feature.to_csv('./coupon/data/'+set_name,index=None)\n",
    "    \n",
    "## generate merchant_feature csv file\n",
    "merchants_feature_extract(set_name='merchant3_feature.csv',data_set=feature3)\n",
    "merchants_feature_extract(set_name='merchant2_feature.csv',data_set=feature2)\n",
    "merchants_feature_extract(set_name='merchant1_feature.csv',data_set=feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# coupon related feature   #############\n",
    "\"\"\"\n",
    "2.coupon related: \n",
    "      discount_rate. discount_man. discount_jian. is_man_jian\n",
    "      day_of_week,day_of_month. (date_received)\n",
    "\"\"\"\n",
    "def calc_discount_rate(s):\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return 1.0-float(s[1])/float(s[0])\n",
    "\n",
    "def get_discount_man(s):\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return int(s[0])\n",
    "    \n",
    "def get_discount_jian(s):\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return int(s[1])\n",
    "    \n",
    "def is_man_jian(s): # if have discount is man_jian,then 1,else 0\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def coupon_related_feature(save_name,data_sets,date_start):\n",
    "    data_set = data_sets.copy()\n",
    "    data_set['day_of_week'] = data_set.date_received.apply(lambda x:date(int(x[0:4]),int(x[4:6]),int(x[6:])).weekday()+1)\n",
    "    data_set['day_of_month'] = data_set.date_received.apply(lambda x:int(x[6:]))\n",
    "    data_set['days_distance'] = data_set.date_received.apply(lambda x:(date(int(x[0:4]),int(x[4:6]),int(x[6:]))-date_start).days)\n",
    "    data_set['discount_man'] =  data_set.discount_rate.apply(get_discount_man)\n",
    "    data_set['discount_jian'] = data_set.discount_rate.apply(get_discount_jian)\n",
    "    data_set['is_man_jian'] = data_set.discount_rate.apply(is_man_jian)\n",
    "    data_set['discount_rate'] = data_set.discount_rate.apply(calc_discount_rate)\n",
    "    d = data_set[['coupon_id']].copy()\n",
    "    d['coupon_count'] = 1\n",
    "    d = d.groupby('coupon_id').agg('sum').reset_index()\n",
    "    data_set = pd.merge(data_set,d,on='coupon_id',how='left')\n",
    "    data_set.to_csv('./coupon/data/'+save_name,index=None)\n",
    "    \n",
    "# generate coupon_related_feature\n",
    "coupon_related_feature(save_name='coupon3_feature.csv',data_sets=dataset3,date_start=date(2016,6,30))\n",
    "coupon_related_feature(save_name='coupon2_feature.csv',data_sets=dataset2,date_start=date(2016,5,14))\n",
    "coupon_related_feature(save_name='coupon1_feature.csv',data_sets=dataset1,date_start=date(2016,4,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# user related feature   #############\n",
    "\"\"\"\n",
    "3.user related: \n",
    "      count_merchant. \n",
    "      user_avg_distance, user_min_distance,user_max_distance. \n",
    "      buy_use_coupon. buy_total. coupon_received.\n",
    "      buy_use_coupon/coupon_received. \n",
    "      buy_use_coupon/buy_total\n",
    "      user_date_datereceived_gap\n",
    "      \n",
    "\"\"\"\n",
    "def get_user_date_datereceived_gap(s):\n",
    "    s = s.split(':')\n",
    "    return (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8])) - \n",
    "            date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days\n",
    "\n",
    "def user_related_features(save_name,data_set,features=['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']):\n",
    "    user = data_set[features].copy()\n",
    "    \n",
    "    t = user[['user_id']].copy()\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    \n",
    "    t1 = user[~user.date.isnull()][['user_id','merchant_id']].copy()\n",
    "    t1.drop_duplicates(inplace=True) # drop the subset['user_id','merchant_id']\n",
    "    #t1.merchant_id = 1\n",
    "    #t1 = t1.groupby('user_id').agg('sum').reset_index()\n",
    "    t1 = t1.groupby('user_id').agg('count').reset_index()\n",
    "    t1.rename(columns = {'merchant_id':'count_merchant'},inplace=True)\n",
    "    \n",
    "    t2 = user[(~user.date.isnull())&(~user.coupon_id.isnull())][['user_id','distance']].copy()\n",
    "    t2.replace(np.nan,-1,inplace=True)\n",
    "    t2.distance = t2.distance.astype(dtype=int,copy=True)\n",
    "    t2.replace(-1,np.nan,inplace=True)\n",
    "    \n",
    "    def distance_features(data,agg_fun,feature_name):\n",
    "        df = data.groupby('user_id').agg(agg_fun).reset_index()\n",
    "        df.rename(columns={'distance':feature_name})\n",
    "        return df\n",
    "    \n",
    "    t3 = distance_features(data=t2,agg_fun='min',feature_name='user_min_distance')\n",
    "    t4 = distance_features(t2,'max','user_max_distance')\n",
    "    t5 = distance_features(t2,'mean','user_mean_distance')\n",
    "    t6 = distance_features(t2,'median','user_median_distance')\n",
    "    \n",
    "    t7 = user[(~user.date.isnull())&(~user.coupon_id.isnull())][['user_id']].copy()\n",
    "    t7['buy_use_coupon'] = 1\n",
    "    t7 = t7.groupby('user_id').agg('sum').reset_index()\n",
    "    \n",
    "    t8 = user[~user.date.isnull()][['user_id']].copy()\n",
    "    t8['buy_total'] = 1\n",
    "    t8 = t8.groupby('user_id').agg('sum').reset_index()\n",
    "    \n",
    "    t9 = user[~user.coupon_id.isnull()][['user_id']].copy()\n",
    "    t9['coupon_received'] = 1\n",
    "    t9 = t9.groupby('user_id').agg('sum').reset_index()\n",
    "    \n",
    "    t10 = user[(~user.date_received.isnull())&(~user.date.isnull())][['user_id','date_received','date']].copy()\n",
    "    t10['user_date_datereceived_gap'] = t10.date+':'+t10.date_received\n",
    "    t10['user_date_datereceived_gap'] = t10['user_date_datereceived_gap'].apply(get_user_date_datereceived_gap)\n",
    "    t10 = t10[['user_id','user_date_datereceived_gap']].copy()\n",
    "    #print(type(t10.user_date_datereceived_gap.values[0]))\n",
    "    #t10.user_date_datereceived_gap = t10.user_date_datereceived_gap.astype(float)\n",
    "    \n",
    "    def data_gap_feature(data,agg_fun,feature_name):\n",
    "        df = data.groupby('user_id').agg(agg_fun).reset_index()\n",
    "        df.rename(columns={'user_date_datereceived_gap':feature_name},inplace=True)\n",
    "        return df\n",
    "    \n",
    "    t11 = data_gap_feature(t10,'mean','avg_user_date_datereceived_gap')\n",
    "    t12 = data_gap_feature(t10,'min','min_user_date_datereceived_gap')\n",
    "    t13 = data_gap_feature(t10,'max','max_user_date_datereceived_gap')\n",
    "    \n",
    "    user_feature = pd.merge(t,t1,on='user_id',how='left')\n",
    "    user_feature = pd.merge(user_feature,t3,on='user_id',how='left')\n",
    "    user_feature = pd.merge(user_feature,t4,on='user_id',how='left')\n",
    "    user_feature = pd.merge(user_feature,t5,on='user_id',how='left')\n",
    "    user_feature = pd.merge(user_feature,t6,on='user_id',how='left')\n",
    "    user_feature = pd.merge(user_feature,t7,on='user_id',how='left')\n",
    "    user_feature = pd.merge(user_feature,t8,on='user_id',how='left')\n",
    "    user_feature = pd.merge(user_feature,t9,on='user_id',how='left')\n",
    "    user_feature = pd.merge(user_feature,t10,on='user_id',how='left')\n",
    "    user_feature = pd.merge(user_feature,t11,on='user_id',how='left')\n",
    "    user_feature = pd.merge(user_feature,t12,on='user_id',how='left')\n",
    "    user_feature = pd.merge(user_feature,t13,on='user_id',how='left')\n",
    "    user_feature.count_merchant.fillna(0,inplace=True)\n",
    "    user_feature.buy_use_coupon.fillna(0,inplace=True)\n",
    "    user_feature['buy_use_coupon_rate'] = user_feature.buy_use_coupon.astype(float).div(user_feature.buy_total.astype(float))\n",
    "    user_feature['user_coupon_transfer_rate'] = user_feature.buy_use_coupon.astype(float).div(user_feature.coupon_received.astype(float))\n",
    "    user_feature.buy_total.fillna(0,inplace=True)\n",
    "    user_feature.coupon_received.fillna(0,inplace=True)\n",
    "    user_feature.to_csv('./coupon/data/'+save_name,index=None)\n",
    "    \n",
    "# generate user feature csv file\n",
    "user_related_features('user3_feature.csv',feature3)\n",
    "user_related_features('user2_feature.csv',feature2)\n",
    "user_related_features('user1_feature.csv',feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################  user_merchant related feature #########################\n",
    "\n",
    "\"\"\"\n",
    "4.user_merchant:\n",
    "      times_user_buy_merchant_before. \n",
    "\"\"\"\n",
    "def user_mechant_add_feature(data_set,new_feature,used_feature):\n",
    "    df = data_set[['user_id','merchant_id',used_feature]].copy()\n",
    "    df1 = df[~df[used_feature].isnull()][['user_id','merchant_id']].copy()\n",
    "    df1[new_feature] = 1\n",
    "    df1 = df1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    df1.drop_duplicates(inplace=True)\n",
    "    return df1\n",
    "\n",
    "def user_merchant_feature(save_name,data_set):\n",
    "    all_user_merchant = data_set[['user_id','merchant_id']].copy()\n",
    "    all_user_merchant.drop_duplicates(inplace=True)\n",
    "    \n",
    "    t = user_mechant_add_feature(data_set=data_set,new_feature='user_merchant_buy_total',used_feature='date')\n",
    "    \n",
    "    t1 = user_mechant_add_feature(data_set=data_set,new_feature='user_merchant_received',used_feature='coupon_id')\n",
    "    \n",
    "    #t2 = data_set[['user_id','merchant_id','date','date_received']].copy()\n",
    "    t2 = data_set[(~data_set.date.isnull())&(~data_set.date_received.isnull())][['user_id','merchant_id']].copy()\n",
    "    t2['user_merchant_buy_use_coupon'] = 1\n",
    "    t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    t2.drop_duplicates(inplace=True)\n",
    "    \n",
    "    t3 = data_set[['user_id','merchant_id']].copy()\n",
    "    t3['user_merchant_any'] = 1 #user_id and merchant_id have relationship\n",
    "    t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    t3.drop_duplicates(inplace=True)\n",
    "    \n",
    "    t4 = data_set[['user_id','merchant_id','date','coupon_id']].copy()\n",
    "    t4 = t4[(~t4.date.isnull())&(t4.coupon_id.isnull())][['user_id','merchant_id']]\n",
    "    t4['user_merchant_buy_common'] = 1 # have coupon,then buy\n",
    "    t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    t4.drop_duplicates(inplace=True)\n",
    "    \n",
    "    user_merchant = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "    user_merchant = pd.merge(user_merchant,t1,on=['user_id','merchant_id'],how='left')\n",
    "    user_merchant = pd.merge(user_merchant,t2,on=['user_id','merchant_id'],how='left')\n",
    "    user_merchant = pd.merge(user_merchant,t3,on=['user_id','merchant_id'],how='left')\n",
    "    user_merchant = pd.merge(user_merchant,t4,on=['user_id','merchant_id'],how='left')\n",
    "            \n",
    "    user_merchant.user_merchant_buy_common.fillna(0,inplace=True)\n",
    "    user_merchant.user_merchant_buy_use_coupon.fillna(0,inplace=True)\n",
    "    user_merchant['user_merchant_coupon_transfer_rate'] = user_merchant.user_merchant_buy_use_coupon.astype(float).\\\n",
    "                                                        div(user_merchant.user_merchant_received.astype(float))\n",
    "    user_merchant['user_merchant_coupon_buy_rate'] = user_merchant.user_merchant_buy_use_coupon.astype(float).\\\n",
    "    div(user_merchant.user_merchant_buy_total.astype(float))\n",
    "    user_merchant['user_merchant_rate'] = user_merchant.user_merchant_buy_total.astype(float).\\\n",
    "    div(user_merchant.user_merchant_any.astype(float))\n",
    "    user_merchant['user_merchant_common_buy_rate'] = user_merchant.user_merchant_buy_common.astype(float).\\\n",
    "    div(user_merchant.user_merchant_buy_total.astype('float'))\n",
    "    user_merchant.to_csv('./coupon/data/'+save_name,index=None)\n",
    "    \n",
    "# generate user_merchant_feature csv file\n",
    "user_merchant_feature('user_merchant3.csv',feature3)\n",
    "user_merchant_feature('user_merchant2.csv',feature2)\n",
    "user_merchant_feature('user_merchant1.csv',feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116204, 11)\n",
      "(262240, 11)\n",
      "(139785, 11)\n"
     ]
    }
   ],
   "source": [
    "############# other feature ##################3\n",
    "\"\"\"\n",
    "5. other feature:\n",
    "      this_month_user_receive_all_coupon_count\n",
    "      this_month_user_receive_same_coupon_count\n",
    "      this_month_user_receive_same_coupon_lastone\n",
    "      this_month_user_receive_same_coupon_firstone\n",
    "      this_day_user_receive_all_coupon_count\n",
    "      this_day_user_receive_same_coupon_count\n",
    "      day_gap_before, day_gap_after  (receive the same coupon)\n",
    "\"\"\"\n",
    "\n",
    "def other_features(save_name, data_set):\n",
    "    t = data_set[['user_id']].copy()\n",
    "    t['this_month_user_receive_all_coupon_count'] = 1\n",
    "    t = t.groupby('user_id').agg('sum').reset_index()\n",
    "    \n",
    "    t1 = data_set[['user_id','coupon_id']].copy()\n",
    "    t1['this_month_user_receive_same_coupon_count'] = 1\n",
    "    t1 = t1.groupby(['user_id','coupon_id']).agg('sum').reset_index()\n",
    "    \n",
    "    t2 = data_set[['user_id','coupon_id','date_received']].copy()\n",
    "    t2 = t2.groupby(['user_id','coupon_id'])['date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "    t2['receive_number'] = t2.date_received.apply(lambda s:len(s.split(':')))\n",
    "    t2 = t2[t2.receive_number>1].copy()\n",
    "    t2['max_date_received'] = t2.date_received.apply(lambda s:np.max([int(d) for d in s.split(':')]))\n",
    "    t2['min_date_received'] = t2.date_received.apply(lambda s:np.min([int(d) for d in s.split(':')]))\n",
    "    t2 = t2[['user_id','coupon_id','min_date_received','max_date_received']].copy()\n",
    "    \n",
    "    t3 = data_set[['user_id','coupon_id','date_received']].copy()\n",
    "    t3 = pd.merge(t3,t2,on=['user_id','coupon_id'],how='left')\n",
    "    t3['this_month_user_receive_same_coupon_lastone'] = t3.max_date_received-t3.date_received.astype(int)\n",
    "    t3['this_month_user_receive_same_coupon_firstone'] = t3.date_received.astype(int) - t3.min_date_received\n",
    "    def is_firstlastone(x):\n",
    "        if x==0:\n",
    "            return 1\n",
    "        elif x>0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1#those only receive once\n",
    "        \n",
    "    t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(is_firstlastone)\n",
    "    t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(is_firstlastone)\n",
    "    t3 = t3[['user_id','coupon_id','date_received','this_month_user_receive_same_coupon_lastone','this_month_user_receive_same_coupon_firstone']].copy()\n",
    "    \n",
    "    t4 = data_set[['user_id','date_received']].copy()\n",
    "    t4['this_day_user_receive_all_coupon_count'] = 1\n",
    "    t4 = t4.groupby(['user_id','date_received']).agg('sum').reset_index()\n",
    "    \n",
    "    t5 = data_set[['user_id','coupon_id','date_received']].copy()\n",
    "    t5['this_day_user_receive_same_coupon_count'] = 1\n",
    "    t5 = t5.groupby(['user_id','coupon_id','date_received']).agg('sum').reset_index()\n",
    "    \n",
    "    t6 = data_set[['user_id','coupon_id','date_received']].copy()\n",
    "    t6 = t6.groupby(['user_id','coupon_id'])['date_received'].apply(lambda x:':'.join(x)).reset_index()\n",
    "    t6.rename(columns={'date_received':'dates'},inplace=True)\n",
    "    \n",
    "    def get_day_gap_before(s):\n",
    "        date_received,dates = s.split('-')\n",
    "        dates = dates.split(':')\n",
    "        gaps = []\n",
    "        for d in dates:\n",
    "            this_gap = (date(int(date_received[:4]),int(date_received[4:6]),int(date_received[6:]))-date(int(d[:4]),int(d[4:6]),int(d[6:]))).days\n",
    "            if this_gap>0:\n",
    "                gaps.append(this_gap)\n",
    "        if len(gaps) == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "        \n",
    "    def get_day_gap_after(s):\n",
    "        date_received,dates = s.split('-')\n",
    "        dates = dates.split(':')\n",
    "        gaps = []\n",
    "        for d in dates:\n",
    "            this_gap = (date(int(d[0:4]),int(d[4:6]),int(d[6:8]))-date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))).days\n",
    "            if this_gap>0:\n",
    "                gaps.append(this_gap)\n",
    "        if len(gaps)==0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "        \n",
    "    t7 = data_set[['user_id','coupon_id','date_received']].copy()\n",
    "    t7 = pd.merge(t7,t6,on=['user_id','coupon_id'],how='left')\n",
    "    t7['date_received_date']=t7.date_received.astype('str')+'-'+t7.dates\n",
    "    t7['day_gap_before'] = t7.date_received_date.apply(get_day_gap_before) # the gap time received the coupon after last one\n",
    "    t7['day_gap_after'] = t7.date_received_date.apply(get_day_gap_after)# the gap time received the coupon before the next one\n",
    "    t7 = t7[['user_id','coupon_id','date_received','day_gap_before','day_gap_after']].copy()\n",
    "    \n",
    "    other_feature = pd.merge(t1,t,on='user_id',how='inner')\n",
    "    other_feature = pd.merge(other_feature,t3,on=['user_id','coupon_id'],how='inner')\n",
    "    other_feature = pd.merge(other_feature,t4,on=['user_id','date_received'],how='inner')\n",
    "    other_feature = pd.merge(other_feature,t5,on=['user_id','coupon_id','date_received'],how='inner')\n",
    "    other_feature = pd.merge(other_feature,t7,on=['user_id','coupon_id','date_received'],how='inner')\n",
    "    other_feature.to_csv('./coupon/data/'+save_name,index=None)\n",
    "    print(other_feature.shape)\n",
    "    \n",
    "    \n",
    "# generate other features of dataset\n",
    "other_features('other_feature3.csv', dataset3)\n",
    "other_features('other_feature2.csv', dataset2)\n",
    "other_features('other_feature1.csv', dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129912, 53)\n",
      "(270741, 54)\n",
      "(141167, 54)\n"
     ]
    }
   ],
   "source": [
    "##################  generate training and testing set ################\n",
    "def get_labels(s):\n",
    "    s = s.split(':')\n",
    "    if s[0].isnull():\n",
    "        return 0\n",
    "    elif (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8]))-date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days<=15:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "file_path = './coupon/data/'\n",
    "def generate_data(file_path,save_name,coupon_file,merchant_file,user_file,user_merchant_file,other_file,data_flag):\n",
    "    coupon = pd.read_csv(file_path+coupon_file,dtype=str)#'coupon3_feature.csv'\n",
    "    merchant = pd.read_csv(file_path+merchant_file,dtype=str)\n",
    "    user = pd.read_csv(file_path+user_file,dtype=str)\n",
    "    user_merchant = pd.read_csv(file_path+user_merchant_file,dtype=str)\n",
    "    other_feature = pd.read_csv(file_path+other_file,dtype=str)\n",
    "    dataset = pd.merge(coupon,merchant,on='merchant_id',how='left')\n",
    "    dataset = pd.merge(dataset,user,on='user_id',how='left')\n",
    "    dataset = pd.merge(dataset,user_merchant,on=['user_id','merchant_id'],how='left')\n",
    "    dataset = pd.merge(dataset,other_feature,on=['user_id','coupon_id','date_received'],how='left')\n",
    "    dataset.drop_duplicates(inplace=True)\n",
    "    print(dataset.shape)\n",
    "\n",
    "    dataset.user_merchant_buy_total.fillna(0,inplace=True)\n",
    "    dataset.user_merchant_any.fillna(0,inplace=True)\n",
    "    dataset.user_merchant_received.fillna(0,inplace=True)\n",
    "    dataset['is_weekend'] = dataset.day_of_week.apply(lambda x: 1 if x in ('6','7') else 0)\n",
    "    weekday_dummies = pd.get_dummies(dataset.day_of_week) # one_hot_encoding\n",
    "    weekday_dummies.columns = ['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "    dataset = pd.concat([dataset,weekday_dummies],axis=1)\n",
    "\n",
    "    if data_flag:\n",
    "        dataset['label'] = dataset.date+':'+dataset.date_received\n",
    "        dataset['label'] = dataset.label.apply(get_labels)\n",
    "\n",
    "    dataset.drop(['merchant_id','day_of_week','coupon_count'],axis=1,inplace=True)\n",
    "    dataset.to_csv(file_path+save_name,index=None)\n",
    "\n",
    "# generate_data\n",
    "generate_data('./coupon/data/','dataset3.csv','coupon3_feature.csv','merchant3_feature.csv','user3_feature.csv',\n",
    "             'user_merchant3.csv','other_feature3.csv',False)\n",
    "generate_data('./coupon/data/','dataset2.csv','coupon2_feature.csv','merchant2_feature.csv','user2_feature.csv',\n",
    "             'user_merchant2.csv','other_feature2.csv',False)\n",
    "generate_data('./coupon/data/','dataset1.csv','coupon1_feature.csv','merchant1_feature.csv','user1_feature.csv',\n",
    "             'user_merchant1.csv','other_feature1.csv',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113640, 6)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-16272"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "113640-129912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
